{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Represent a DNN model as a dataflow by NNgen operators\n",
    "--------------------\n",
    "\n",
    "In NNgen, a DNN model is defined by \"define and run\" manner.\n",
    "You can build up a DNN model by chaining NNgen operators.\n",
    "\n",
    "For the supported NNgen operator list, please see \"nngen/operators/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import nngen as ng\n",
    "\n",
    "\n",
    "# data types\n",
    "act_dtype = ng.int16\n",
    "weight_dtype = ng.int16\n",
    "bias_dtype = ng.int16\n",
    "scale_dtype = ng.int16\n",
    "\n",
    "# input\n",
    "input_layer = ng.placeholder(dtype=act_dtype,\n",
    "                             shape=(1, 32, 32, 3),  # N, H, W, C\n",
    "                             name='input_layer')\n",
    "\n",
    "# layer 0: conv2d (with bias and scale (= batchnorm)), relu, max_pool\n",
    "w0 = ng.variable(dtype=weight_dtype,\n",
    "                 shape=(64, 3, 3, 3),  # Och, Ky, Kx, Ich\n",
    "                 name='w0')\n",
    "b0 = ng.variable(dtype=bias_dtype,\n",
    "                 shape=(w0.shape[0],), name='b0')\n",
    "s0 = ng.variable(dtype=scale_dtype,\n",
    "                 shape=(w0.shape[0],), name='s0')\n",
    "\n",
    "a0 = ng.conv2d(input_layer, w0,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b0,\n",
    "               scale=s0,\n",
    "               act_func=ng.relu,\n",
    "               sum_dtype=ng.int64)\n",
    "\n",
    "a0p = ng.max_pool_serial(a0,\n",
    "                         ksize=(1, 2, 2, 1),\n",
    "                         strides=(1, 2, 2, 1))\n",
    "\n",
    "# layer 1: conv2d, relu, reshape\n",
    "w1 = ng.variable(weight_dtype,\n",
    "                 shape=(64, 3, 3, a0.shape[-1]),\n",
    "                 name='w1')\n",
    "b1 = ng.variable(bias_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='b1')\n",
    "s1 = ng.variable(scale_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='s1')\n",
    "\n",
    "a1 = ng.conv2d(a0p, w1,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b1,\n",
    "               scale=s1,\n",
    "               act_func=ng.relu,\n",
    "               sum_dtype=ng.int64)\n",
    "\n",
    "a1r = ng.reshape(a1, [1, -1])\n",
    "\n",
    "# layer 2: full-connection, relu\n",
    "w2 = ng.variable(weight_dtype,\n",
    "                 shape=(256, a1r.shape[-1]),\n",
    "                 name='w2')\n",
    "b2 = ng.variable(bias_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='b2')\n",
    "s2 = ng.variable(scale_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='s2')\n",
    "\n",
    "a2 = ng.matmul(a1r, w2,\n",
    "               bias=b2,\n",
    "               scale=s2,\n",
    "               transposed_b=True,\n",
    "               act_func=ng.relu,\n",
    "               sum_dtype=ng.int64)\n",
    "\n",
    "# layer 3: full-connection, relu\n",
    "w3 = ng.variable(weight_dtype,\n",
    "                 shape=(10, a2.shape[-1]),\n",
    "                 name='w3')\n",
    "b3 = ng.variable(bias_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='b3')\n",
    "s3 = ng.variable(scale_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='s3')\n",
    "\n",
    "# output\n",
    "output_layer = ng.matmul(a2, w3,\n",
    "                         bias=b3,\n",
    "                         scale=s3,\n",
    "                         transposed_b=True,\n",
    "                         name='output_layer',\n",
    "                         sum_dtype=ng.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Assign quantized weights to the NNgen operators\n",
    "--------------------\n",
    "\n",
    "Constructed NNgen operators contain no weight values. To verify the constructed NNgen dataflow as a software in an integer precision, weight values must be assigned to each ng.variable by \"set_value\" method.\n",
    "\n",
    "In this example, random integer values are produced by NumPy, and are assigned. However, in real cases, actual integer weight values obtained by a DNN framework should be assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w0_value = np.random.normal(size=w0.length).reshape(w0.shape)\n",
    "w0_value = np.clip(w0_value, -5.0, 5.0)\n",
    "w0_value = w0_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0\n",
    "w0_value = np.round(w0_value).astype(np.int64)\n",
    "w0.set_value(w0_value)\n",
    "\n",
    "b0_value = np.random.normal(size=b0.length).reshape(b0.shape)\n",
    "b0_value = np.clip(b0_value, -5.0, 5.0)\n",
    "b0_value = b0_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0 / 100.0\n",
    "b0_value = np.round(b0_value).astype(np.int64)\n",
    "b0.set_value(b0_value)\n",
    "\n",
    "s0_value = np.ones(s0.shape, dtype=np.int64)\n",
    "s0.set_value(s0_value)\n",
    "\n",
    "w1_value = np.random.normal(size=w1.length).reshape(w1.shape)\n",
    "w1_value = np.clip(w1_value, -5.0, 5.0)\n",
    "w1_value = w1_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0\n",
    "w1_value = np.round(w1_value).astype(np.int64)\n",
    "w1.set_value(w1_value)\n",
    "\n",
    "b1_value = np.random.normal(size=b1.length).reshape(b1.shape)\n",
    "b1_value = np.clip(b1_value, -5.0, 5.0)\n",
    "b1_value = b1_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0 / 100.0\n",
    "b1_value = np.round(b1_value).astype(np.int64)\n",
    "b1.set_value(b1_value)\n",
    "\n",
    "s1_value = np.ones(s1.shape, dtype=np.int64)\n",
    "s1.set_value(s1_value)\n",
    "\n",
    "w2_value = np.random.normal(size=w2.length).reshape(w2.shape)\n",
    "w2_value = np.clip(w2_value, -5.0, 5.0)\n",
    "w2_value = w2_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0\n",
    "w2_value = np.round(w2_value).astype(np.int64)\n",
    "w2.set_value(w2_value)\n",
    "\n",
    "b2_value = np.random.normal(size=b2.length).reshape(b2.shape)\n",
    "b2_value = np.clip(b2_value, -5.0, 5.0)\n",
    "b2_value = b2_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0 / 100.0\n",
    "b2_value = np.round(b2_value).astype(np.int64)\n",
    "b2.set_value(b2_value)\n",
    "\n",
    "s2_value = np.ones(s2.shape, dtype=np.int64)\n",
    "s2.set_value(s2_value)\n",
    "\n",
    "w3_value = np.random.normal(size=w3.length).reshape(w3.shape)\n",
    "w3_value = np.clip(w3_value, -5.0, 5.0)\n",
    "w3_value = w3_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0\n",
    "w3_value = np.round(w3_value).astype(np.int64)\n",
    "w3.set_value(w3_value)\n",
    "\n",
    "b3_value = np.random.normal(size=b3.length).reshape(b3.shape)\n",
    "b3_value = np.clip(b3_value, -5.0, 5.0)\n",
    "b3_value = b3_value * (2.0 ** (weight_dtype.width - 1) - 1) / 5.0 / 100.0\n",
    "b3_value = np.round(b3_value).astype(np.int64)\n",
    "b3.set_value(b3_value)\n",
    "\n",
    "s3_value = np.ones(s3.shape, dtype=np.int64)\n",
    "s3.set_value(s3_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Assign hardware attributes\n",
    "--------------------\n",
    "\n",
    "The default hardware organization is not properly parallelized. According to a performance requirement and resource constraints, parallelism in various directions can be configured via \"attribute\" method of each operator.\n",
    "\n",
    "NNgen hardware executes a DNN model in integer precision. Thus, right-shift operations are inserted to the tail of (almost) each operator. The amount of right-shift (shamt) also can be assigned via \"attribute\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d, matmul\n",
    "# par_ich: parallelism in input-channel\n",
    "# par_och: parallelism in output-channel\n",
    "# par_col: parallelism in pixel column\n",
    "# par_row: parallelism in pixel row\n",
    "# cshamt_out: right shift amount after applying bias/scale\n",
    "\n",
    "par_ich = 2\n",
    "par_och = 2\n",
    "cshamt_out = weight_dtype.width + 1\n",
    "\n",
    "a0.attribute(par_ich=par_ich, par_och=par_och,\n",
    "             cshamt_out=weight_dtype.width + 1)\n",
    "a1.attribute(par_ich=par_ich, par_och=par_och,\n",
    "             cshamt_out=weight_dtype.width + 1)\n",
    "a2.attribute(par_ich=par_ich, par_och=par_och,\n",
    "             cshamt_out=weight_dtype.width + 1)\n",
    "output_layer.attribute(par_ich=par_ich, par_och=par_och,\n",
    "                       cshamt_out=weight_dtype.width + 1)\n",
    "\n",
    "# max_pool\n",
    "# par: parallelism in in/out channel\n",
    "\n",
    "par = par_och\n",
    "\n",
    "a0p.attribute(par=par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Verify the DNN model behavior by executing the NNgen dataflow as a software\n",
    "--------------------\n",
    "\n",
    "After weight values are assigned, the constructed NNgen dataflow can be executed as a software to verify a quantized DNN model. \"ng.eval\" method evaluates the NNgen dataflow according to input values passed via method arguments.\n",
    "\n",
    "In this example, random integer values are produced by NumPy, and are assigned as an input. However, actual integer input values, such as image data opened by PIL, should be assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9008  2590  -828  4137 -1347  1913  3268 -9269 16403 -9141]]\n"
     ]
    }
   ],
   "source": [
    "input_layer_value = np.random.normal(size=input_layer.length).reshape(input_layer.shape)\n",
    "input_layer_value = np.clip(input_layer_value, -5.0, 5.0)\n",
    "input_layer_value = input_layer_value * (2.0 ** (input_layer.dtype.width - 1) - 1) / 5.0\n",
    "input_layer_value = np.round(input_layer_value).astype(np.int64)\n",
    "\n",
    "eval_outs = ng.eval([output_layer], input_layer=input_layer_value)\n",
    "output_layer_value = eval_outs[0]\n",
    "\n",
    "print(output_layer_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Convert the NNgen dataflow to a hardware description (Verilog HDL and IP-XACT)\n",
    "--------------------\n",
    "\n",
    "After all the weights are assigned and the hardware attributes are configured, the NNgen dataflow is ready to be converted to an actual hardware description.\n",
    "\n",
    "You can specify the hardware parameters, such as a data width of the AXI interface and system-wide signal names, via the \"config\" argument. Please see \"nngen/verilog.py\" for all the list of configurable hardware parameters.\n",
    "\n",
    "NNgen generates an all-inclusive dedicated hardware design for an input DNN model, which includes parallel processing elements, on-chip memories, on-chip network between the processing elements and the on-chip memories, a DMA controller between off-chip memories and on-chip memories, and FSM-based control circuits. Therefore, no external control, such as DMA on CPU is required after the generated hardware begins a computation.\n",
    "\n",
    "NNgen supports 3 types of output: 1) Veriloggen object, which is Python-based high-level hardware abstraction, 2) IP-XACT, which is a common IP-core format, and 3) Verilog HDL RTL as a text file.\n",
    "A generated Veriloggen object can be easily verified by a testing mechanism of Veriloggen and a Verilog simulator.\n",
    "A generated IP-XACT IP-core can be integrated with other components via AMBA AXI4 interface on an FPGA.\n",
    "\n",
    "All weight parameters are zipped into a single np.ndarray by \"ng.export_ndarray\" method. This array will be utilized in actual FPGA platform later. So please save it using \"np.save\" method as a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNgen: Neural Network Accelerator Generator (version 1.1)\n",
      "[IP-XACT]\n",
      "  Output: hello_nngen\n",
      "[Configuration]\n",
      "(AXI Master Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "(AXI Slave Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "[Schedule Table]\n",
      "(Stage 0)\n",
      "(Stage 1)\n",
      "  <conv2d None dtype:int16 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int64 par_ich:2 par_och:2 concur_och:4 stationary:filter keep_input default_addr:8481984 g_index:0 l_index:1 word_alignment:2 aligned_shape:(1, 32, 32, 64) scale_factor:1.000000>\n",
      "  | <placeholder input_layer dtype:int16 shape:(1, 32, 32, 3) default_addr:64 g_index:2 word_alignment:2 aligned_shape:(1, 32, 32, 4) scale_factor:1.000000>\n",
      "  | <variable w0 dtype:int16 shape:(64, 3, 3, 3) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64, 3, 3, 4) scale_factor:1.000000>\n",
      "  | <variable b0 dtype:int16 shape:(64,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:1.000000>\n",
      "  | <variable s0 dtype:int16 shape:(64,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:1.000000>\n",
      "(Stage 2)\n",
      "  <max_pool_serial None dtype:int16 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:8613056 g_index:0 l_index:2 word_alignment:2 aligned_shape:(1, 16, 16, 64) scale_factor:1.000000>\n",
      "  | <conv2d None dtype:int16 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int64 par_ich:2 par_och:2 concur_och:4 stationary:filter keep_input default_addr:8481984 g_index:0 l_index:1 word_alignment:2 aligned_shape:(1, 32, 32, 64) scale_factor:1.000000>\n",
      "(Stage 3)\n",
      "  <conv2d None dtype:int16 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int64 par_ich:2 par_och:2 concur_och:4 stationary:filter default_addr:8645824 g_index:0 l_index:3 word_alignment:2 aligned_shape:(1, 16, 16, 64) scale_factor:1.000000>\n",
      "  | <max_pool_serial None dtype:int16 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:8613056 g_index:0 l_index:2 word_alignment:2 aligned_shape:(1, 16, 16, 64) scale_factor:1.000000>\n",
      "  | <variable w1 dtype:int16 shape:(64, 3, 3, 64) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64, 3, 3, 64) scale_factor:1.000000>\n",
      "  | <variable b1 dtype:int16 shape:(64,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:1.000000>\n",
      "  | <variable s1 dtype:int16 shape:(64,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:1.000000>\n",
      "(Stage 4)\n",
      "  <_lazy_reshape None dtype:int16 shape:(1, 16384) alias_of:<conv2d> default_addr:8645824 g_index:0 l_index:3 word_alignment:2 aligned_shape:(1, 16384) scale_factor:1.000000>\n",
      "  | <conv2d None dtype:int16 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int64 par_ich:2 par_och:2 concur_och:4 stationary:filter default_addr:8645824 g_index:0 l_index:3 word_alignment:2 aligned_shape:(1, 16, 16, 64) scale_factor:1.000000>\n",
      "(Stage 5)\n",
      "  <matmul None dtype:int16 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:17 act_func:relu sum_dtype:int64 par_left_col:2 par_out_col:2 concur_out_col:2 stationary:right keep_left default_addr:8678592 g_index:0 l_index:4 word_alignment:2 aligned_shape:(1, 256) scale_factor:1.000000>\n",
      "  | <_lazy_reshape None dtype:int16 shape:(1, 16384) alias_of:<conv2d> default_addr:8645824 g_index:0 l_index:3 word_alignment:2 aligned_shape:(1, 16384) scale_factor:1.000000>\n",
      "  | <variable w2 dtype:int16 shape:(256, 16384) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(256, 16384) scale_factor:1.000000>\n",
      "  | <variable b2 dtype:int16 shape:(256,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(256,) scale_factor:1.000000>\n",
      "  | <variable s2 dtype:int16 shape:(256,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(256,) scale_factor:1.000000>\n",
      "(Stage 6)\n",
      "  <matmul output_layer dtype:int16 shape:(1, 10) bias:(10,) scale:(10,) cshamt_out:17 sum_dtype:int64 par_left_col:2 par_out_col:2 concur_out_col:128 stationary:right keep_left keep_right default_addr:0 g_index:1 word_alignment:2 aligned_shape:(1, 10) scale_factor:1.000000>\n",
      "  | <matmul None dtype:int16 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:17 act_func:relu sum_dtype:int64 par_left_col:2 par_out_col:2 concur_out_col:2 stationary:right keep_left default_addr:8678592 g_index:0 l_index:4 word_alignment:2 aligned_shape:(1, 256) scale_factor:1.000000>\n",
      "  | <variable w3 dtype:int16 shape:(10, 256) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(10, 256) scale_factor:1.000000>\n",
      "  | <variable b3 dtype:int16 shape:(10,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(10,) scale_factor:1.000000>\n",
      "  | <variable s3 dtype:int16 shape:(10,) default_addr:8256 g_index:3 word_alignment:2 aligned_shape:(10,) scale_factor:1.000000>\n",
      "[RAM (spec: num)]\n",
      "  32-bit 16384-entry 2-port 1-bank RAM: 2\n",
      "  32-bit 8192-entry 2-port 1-bank RAM: 1\n",
      "  32-bit 512-entry 2-port 1-bank RAM: 9\n",
      "  32-bit 256-entry 2-port 1-bank RAM: 2\n",
      "  32-bit 128-entry 2-port 1-bank RAM: 22\n",
      "[Substream (spec: num)]\n",
      "  ('acc_rshift_round_frac', (64, 0, True, 64, 0, True)): 2\n",
      "  ('add_tree', (64, 0, True, 2)): 2\n",
      "  ('add_tree', (64, 0, True, 18)): 2\n",
      "  ('mul_rshift_clip', (64, 0, True, 16, 0, True, 80, 0, True, 16, 0, True)): 2\n",
      "  ('mul_rshift_round_madd', (16, 0, True, 16, 0, True, 32, 0, True)): 36\n",
      "  ('reduce_max', (16, 0, True)): 2\n",
      "[Stream (spec: num)]\n",
      "  (((<class 'nngen.operator.conv2d.conv2d'>, <dtype int16>, <dtype int16>, <dtype int16>, <dtype int16>), <dtype int16>, 1), 3, 3, None, <dtype int64>, 2, 2, 1, 1, 9, 36): 1\n",
      "  (((<class 'nngen.operator.pool_serial.max_pool_serial'>, <dtype int16>), <dtype int16>, 2), 2, 2, True, 2): 1\n",
      "  (((<class 'nngen.operator.basic._lazy_reshape'>, <dtype int16>), <dtype int16>, 1), True): 1\n",
      "  (((<class 'nngen.operator.matmul.matmul'>, <dtype int16>, <dtype int16>, <dtype int16>, <dtype int16>), <dtype int16>, 1), 1, 1, None, <dtype int64>, 2, 2, 1, 1, 1, 4): 1\n",
      "[Control (name (# states: num))]\n",
      "  main_fsm (# states: 58)\n",
      "  control_conv2d_4 (# states: 56)\n",
      "  control_max_pool_serial_5 (# states: 26)\n",
      "  control_matmul_14 (# states: 41)\n",
      "[Register Map]\n",
      "   0 (O): header0 (default: 0)\n",
      "   4 (O): header1 (default: 0)\n",
      "   8 (O): header2 (default: 0)\n",
      "  12 (O): header3 (default: 0)\n",
      "  16 (I): Start (set '1' to run)\n",
      "  20 (O): Busy (returns '1' when running)\n",
      "  24 (I): Reset (set '1' to initialize internal logic)\n",
      "  28 (O): Opcode from extern objects to SW (returns '0' when idle)\n",
      "  32 (I): Resume extern objects (set '1' to resume)\n",
      "  36 (I): Global address offset (default: 0)\n",
      "  40 (I): Address of temporal storages (size: 193KB)\n",
      "  44 (I): Address of output (matmul) 'output_layer' (size: 64B, dtype: int16, shape: (1, 10), alignment: 2 words (4 bytes)), aligned shape: (1, 10)\n",
      "  48 (I): Address of placeholder 'input_layer' (size: 8KB, dtype: int16, shape: (1, 32, 32, 3), alignment: 2 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  52 (I): Address of variables 'w0', 'b0', 's0', 'w1', 'b1', 's1', 'w2', 'b2', 's2', 'w3', 'b3', 's3' (size: 8276KB)\n",
      "[Default Memory Map (start - end)] (entire range: [0 - 8679103], size: 8476KB)\n",
      "  [      0 -      63]: output (matmul) 'output_layer' (size: 64B, dtype: int16, shape: (1, 10), alignment: 2 words (4 bytes)), aligned shape: (1, 10)\n",
      "  [     64 -    8255]: placeholder 'input_layer' (size: 8KB, dtype: int16, shape: (1, 32, 32, 3), alignment: 2 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  [   8256 -   12863]: variable 'w0' (size: 5KB, dtype: int16, shape: (64, 3, 3, 3), alignment: 2 words (4 bytes)), aligned shape: (64, 3, 3, 4)\n",
      "  [  12864 -   12991]: variable 'b0' (size: 128B, dtype: int16, shape: (64,), alignment: 2 words (4 bytes)), aligned shape: (64,)\n",
      "  [  12992 -   13119]: variable 's0' (size: 128B, dtype: int16, shape: (64,), alignment: 2 words (4 bytes)), aligned shape: (64,)\n",
      "  [  13120 -   86847]: variable 'w1' (size: 72KB, dtype: int16, shape: (64, 3, 3, 64), alignment: 2 words (4 bytes)), aligned shape: (64, 3, 3, 64)\n",
      "  [  86848 -   86975]: variable 'b1' (size: 128B, dtype: int16, shape: (64,), alignment: 2 words (4 bytes)), aligned shape: (64,)\n",
      "  [  86976 -   87103]: variable 's1' (size: 128B, dtype: int16, shape: (64,), alignment: 2 words (4 bytes)), aligned shape: (64,)\n",
      "  [  87104 - 8475711]: variable 'w2' (size: 8192KB, dtype: int16, shape: (256, 16384), alignment: 2 words (4 bytes)), aligned shape: (256, 16384)\n",
      "  [8475712 - 8476223]: variable 'b2' (size: 512B, dtype: int16, shape: (256,), alignment: 2 words (4 bytes)), aligned shape: (256,)\n",
      "  [8476224 - 8476735]: variable 's2' (size: 512B, dtype: int16, shape: (256,), alignment: 2 words (4 bytes)), aligned shape: (256,)\n",
      "  [8476736 - 8481855]: variable 'w3' (size: 5KB, dtype: int16, shape: (10, 256), alignment: 2 words (4 bytes)), aligned shape: (10, 256)\n",
      "  [8481856 - 8481919]: variable 'b3' (size: 64B, dtype: int16, shape: (10,), alignment: 2 words (4 bytes)), aligned shape: (10,)\n",
      "  [8481920 - 8481983]: variable 's3' (size: 64B, dtype: int16, shape: (10,), alignment: 2 words (4 bytes)), aligned shape: (10,)\n",
      "  [8481984 - 8679103]: temporal storages (size: 193KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IP-XACT was generated. Check the current directory.\n"
     ]
    }
   ],
   "source": [
    "silent = False\n",
    "axi_datawidth = 32\n",
    "\n",
    "# to Veriloggen object\n",
    "# targ = ng.to_veriloggen([output_layer], 'hello_nngen', silent=silent,\n",
    "#                        config={'maxi_datawidth': axi_datawidth})\n",
    "\n",
    "# to IP-XACT (the method returns Veriloggen object, as well as to_veriloggen)\n",
    "targ = ng.to_ipxact([output_layer], 'hello_nngen', silent=silent,\n",
    "                    config={'maxi_datawidth': axi_datawidth})\n",
    "print('# IP-XACT was generated. Check the current directory.')\n",
    "\n",
    "# to Verilog HDL RTL (the method returns a source code text)\n",
    "# rtl = ng.to_verilog([output_layer], 'hello_nngen', silent=silent,\n",
    "#                    config={'maxi_datawidth': axi_datawidth})\n",
    "\n",
    "# to memory image:\n",
    "# on a real FPGA platform, this image will be used as a part of the model definition.\n",
    "param_filename = 'hello_nngen.npy'\n",
    "chunk_size = 64\n",
    "\n",
    "param_data = ng.export_ndarray([output_layer], chunk_size)\n",
    "np.save(param_filename, param_data)\n",
    "\n",
    "# If you don't check the RTL behavior, exit here.\n",
    "# print('# Skipping RTL simulation. If you simulate the RTL behavior, comment out the next line.')\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Simulate the generated hardware by Veriloggen and Verilog simulator\n",
    "--------------------\n",
    "\n",
    "If you want to reduce the development time, you can skip this section for Verilog simulation.\n",
    "\n",
    "If you generate a hardware as Veriloggen object or IP-XACT, you can simulate the hardware behavior on Verilog simulator via the testing mechanism on Veriloggen.\n",
    "\n",
    "Before the hardware runs, the input data and weight values should be located on the shared off-chip memory. In Verilog simulation in the example, there is a np.ndarray object to represent a dump image of the off-chip memory. You can copy the pre-computed values to the memory image by \"axi.set_memory\" method.\n",
    "\n",
    "\"param_data\" is the unified parameter data of all variables and constants. Locations of the located data are configurable, which can be changed from the CPU via the configuration register of the NNgen hardware. In the following example, the head address of unified parameter data (variblae_addr) is calculated by the same rule as the address calculator in the NNgen compiler.\n",
    "\n",
    "\"ctrl\" method in the following example is an emulation of a control program on the CPU, which is actually an FSM circuit of the control sequence synthesized by the procedural high-level synthesis compiler of Veriloggen. By \"ng.sim.start\" method, the program writes '1' to the \"start\" register of the NNgen hardware. Then the hardware begins the computation, and the CPU waits until the computation finishes by \"ng.sim.wait\" method.\n",
    "\n",
    "### Data alignment, and \"word_alignment\" and \"aligned_shape\"\n",
    "\n",
    "**Note that all the input, weight, and output data should be located along with their alignments.** Especially, using a narrower data width (for any data) than the AXI interconnect interface and applying the parallelization via the hardware attribute will require special cares of data arrangement. In a synthesis log, you can find the **word_alignment** and **aligned_shape** for each placeholder, variable, operator. When putting corresponding data on an off-chip memory, a padding will be required according to the word alignment. The difference between the original shape and the aligned shape is the size of padding. In NNgen, padding is required only at an inner-most dimension.\n",
    "\n",
    "Unified variable images, such as \"param_data\", are already aligned according to the word alignment. So you don't have to rearrange the data alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# start\n",
      "# end\n",
      "# execution cycles:     3724629\n",
      "OK (           0           0 ) orig:         9008  check:         9008\n",
      "OK (           0           1 ) orig:         2590  check:         2590\n",
      "OK (           0           2 ) orig:         -828  check:         -828\n",
      "OK (           0           3 ) orig:         4137  check:         4137\n",
      "OK (           0           4 ) orig:        -1347  check:        -1347\n",
      "OK (           0           5 ) orig:         1913  check:         1913\n",
      "OK (           0           6 ) orig:         3268  check:         3268\n",
      "OK (           0           7 ) orig:        -9269  check:        -9269\n",
      "OK (           0           8 ) orig:        16403  check:        16403\n",
      "OK (           0           9 ) orig:        -9141  check:        -9141\n",
      "# verify: PASSED\n",
      "- hello_nngen.out/out.v:1092: Verilog $finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from veriloggen import *\n",
    "import veriloggen.thread as vthread\n",
    "import veriloggen.types.axi as axi\n",
    "\n",
    "chunk_size = 64\n",
    "outputfile = 'hello_nngen.out'\n",
    "filename = 'hello_nngen.v'\n",
    "# simtype = 'iverilog'\n",
    "simtype = 'verilator'\n",
    "\n",
    "param_bytes = len(param_data)\n",
    "\n",
    "variable_addr = int(\n",
    "    math.ceil((input_layer.addr + input_layer.memory_size) / chunk_size)) * chunk_size\n",
    "check_addr = int(math.ceil((variable_addr + param_bytes) / chunk_size)) * chunk_size\n",
    "tmp_addr = int(math.ceil((check_addr + output_layer.memory_size) / chunk_size)) * chunk_size\n",
    "\n",
    "memimg_datawidth = 32\n",
    "mem = np.zeros([1024 * 1024 * 256 // memimg_datawidth], dtype=np.int64)\n",
    "mem = mem + [100]\n",
    "\n",
    "# placeholder\n",
    "axi.set_memory(mem, input_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, input_layer.addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_ich))\n",
    "\n",
    "# parameters (variable and constant)\n",
    "axi.set_memory(mem, param_data, memimg_datawidth,\n",
    "               8, variable_addr)\n",
    "\n",
    "# verification data\n",
    "axi.set_memory(mem, output_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, check_addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_och))\n",
    "\n",
    "# test controller\n",
    "m = Module('test')\n",
    "params = m.copy_params(targ)\n",
    "ports = m.copy_sim_ports(targ)\n",
    "clk = ports['CLK']\n",
    "resetn = ports['RESETN']\n",
    "rst = m.Wire('RST')\n",
    "rst.assign(Not(resetn))\n",
    "\n",
    "# AXI memory model\n",
    "if outputfile is None:\n",
    "    outputfile = os.path.splitext(os.path.basename(__file__))[0] + '.out'\n",
    "\n",
    "memimg_name = 'memimg_' + outputfile\n",
    "\n",
    "memory = axi.AxiMemoryModel(m, 'memory', clk, rst,\n",
    "                            datawidth=axi_datawidth,\n",
    "                            memimg=mem, memimg_name=memimg_name,\n",
    "                            memimg_datawidth=memimg_datawidth)\n",
    "memory.connect(ports, 'maxi')\n",
    "\n",
    "# AXI-Slave controller\n",
    "_saxi = vthread.AXIMLite(m, '_saxi', clk, rst, noio=True)\n",
    "_saxi.connect(ports, 'saxi')\n",
    "\n",
    "# timer\n",
    "time_counter = m.Reg('time_counter', 32, initval=0)\n",
    "seq = Seq(m, 'seq', clk, rst)\n",
    "seq(\n",
    "    time_counter.inc()\n",
    ")\n",
    "\n",
    "\n",
    "def ctrl():\n",
    "    for i in range(100):\n",
    "        pass\n",
    "\n",
    "    ng.sim.set_global_addrs(_saxi, tmp_addr)\n",
    "\n",
    "    start_time = time_counter.value\n",
    "    ng.sim.start(_saxi)\n",
    "\n",
    "    print('# start')\n",
    "\n",
    "    ng.sim.wait(_saxi)\n",
    "    end_time = time_counter.value\n",
    "\n",
    "    print('# end')\n",
    "    print('# execution cycles: %d' % (end_time - start_time))\n",
    "\n",
    "    # verify\n",
    "    ok = True\n",
    "    for bat in range(output_layer.shape[0]):\n",
    "        for x in range(output_layer.shape[1]):\n",
    "            orig = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                    output_layer.addr, act_dtype.width)\n",
    "            check = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                     check_addr, act_dtype.width)\n",
    "\n",
    "            if vthread.verilog.NotEql(orig, check):\n",
    "                print('NG (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "                ok = False\n",
    "            else:\n",
    "                print('OK (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "\n",
    "    if ok:\n",
    "        print('# verify: PASSED')\n",
    "    else:\n",
    "        print('# verify: FAILED')\n",
    "\n",
    "    vthread.finish()\n",
    "\n",
    "\n",
    "th = vthread.Thread(m, 'th_ctrl', clk, rst, ctrl)\n",
    "fsm = th.start()\n",
    "\n",
    "uut = m.Instance(targ, 'uut',\n",
    "                 params=m.connect_params(targ),\n",
    "                 ports=m.connect_ports(targ))\n",
    "\n",
    "# simulation.setup_waveform(m, uut)\n",
    "simulation.setup_clock(m, clk, hperiod=5)\n",
    "init = simulation.setup_reset(m, resetn, m.make_reset(), period=100, polarity='low')\n",
    "\n",
    "init.add(\n",
    "    Delay(10000000),\n",
    "    Systask('finish'),\n",
    ")\n",
    "\n",
    "# output source code\n",
    "if filename is not None:\n",
    "    m.to_verilog(filename)\n",
    "\n",
    "# run simulation\n",
    "sim = simulation.Simulator(m, sim=simtype)\n",
    "rslt = sim.run(outputfile=outputfile)\n",
    "\n",
    "print(rslt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
